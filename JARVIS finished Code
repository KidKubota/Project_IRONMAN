
import mediapipe as mp
import pyttsx3
import os
import threading
import pyautogui
import random
import speech_recognition as sr
import ctypes
import pyttsx3 
import ctypes 
import keyboard
import screen_brightness_control as sbc
from pypresence import Presence
import time
import requests
import random
import tkinter as tk
import requests
from datetime import datetime
import threading
import requests
from spotipy.oauth2 import SpotifyOAuth
import threading
import speech_recognition as sr
from playsound import playsound
import webbrowser
import speech_recognition as sr
import pyttsx3
import psutil
import sys
import pyttsx3
import queue
import threading
import cv2
import numpy as np
import pyautogui
import threading
import webbrowser
import time
import os
import os
import time
from plyer import notification
import os
import time
import threading
from plyer import notification
import pyttsx3
import psutil
import speedtest
import time
from tkinter import messagebox
from bleak import BleakScanner
import pyttsx3
import time
import asyncio
import subprocess
import playsound

import os
import sys
import pyttsx3
import playsound
import random
import time
from PIL import Image
import tkinter as tk
import winsound
from PIL import Image, ImageTk  # Import ImageTk here
import tkinter as tk
import requests
import math
import sys

import requests
import geopy.distance




# Define paths and expected key
KEY_PATH = r"c:\Users\pjtru\OneDrive\Projects\ownerkey.txt"
EXPECTED_KEY = "Bill_Cipher"
CREEPY_AUDIO_PATH = r"c:\Users\pjtru\OneDrive\Projects\jumpscare-sound-effect.mp3"
SCARY_IMAGE_PATH = r"c:\Users\pjtru\OneDrive\Projects\Screenshot 2025-05-02 195430.png"  # Your scary image path
def verify_owner_key():
    if not os.path.exists(KEY_PATH):
        return False
    with open(KEY_PATH, "r") as f:
        key = f.read().strip()
    return key == EXPECTED_KEY

def scare_intruder():
    # Static noise (to enhance the scare effect)
    static_noise()


    # Scary audio and speech
    engine = pyttsx3.init()
    engine.setProperty('rate', 130)
    engine.say("I warned you.")
    engine.runAndWait()

    playsound.playsound(CREEPY_AUDIO_PATH)

    # Optional: Lock, exit, or log the intruder
    sys.exit("Unauthorized user. Exiting...")

def static_noise():
    """Simulate static noise for extra scare effect"""
    print("üéß Static noise triggered!")
    for _ in range(26):  # Random intervals to simulate static
        frequency = random.randint(200, 2000)  # Simulate random static frequencies
        duration = random.randint(50, 300)  # Random duration of each "static" sound
        winsound.Beep(frequency, duration)
        time.sleep(random.uniform(0.01, 0.001))  # Random short delay between static noise bursts


def flash_scary_image():
    """Display a scary image as part of the scare"""
    print("üñºÔ∏è Flashing scary image!")
    
    # Create a Tkinter window
    root = tk.Tk()
    root.title("Intruder Detected!")
    
    # Load the scary image
    scary_image = Image.open(SCARY_IMAGE_PATH)
    scary_image = scary_image.resize((800, 600))  # Resize the image to fit the screen
    
    # Convert the image to a Tkinter-compatible photo object
    photo = ImageTk.PhotoImage(scary_image)

    # Create a label to display the image
    label = tk.Label(root, image=photo)
    label.pack()

    # Flash the image multiple times
    for _ in range(3):  # Flash it 3 times
        root.deiconify()  # Show the image
        time.sleep(0.5)  # Display for 0.5 seconds
        root.withdraw()  # Hide the image
        time.sleep(0.5)  # Wait for 0.5 seconds

    root.destroy()  # Close the window after flashing


# üîê Run check at startup
if not verify_owner_key():
    scare_intruder()
else:
    print("‚úÖ Ownership verified. Welcome back, sir.")

 



def check_network_connection():
    try:
        return bool(psutil.net_if_addrs()) and bool(psutil.net_connections())
    except psutil.Error:
        return False

def check_internet_speed(threshold=2.5):
    try:
        st = speedtest.Speedtest()
        speed_mbps = st.download() / 1_000_000
        return speed_mbps < threshold
    except Exception:
        return True  # Assume slow if check fails

def monitor_network():
    was_disconnected = False
    last_speed_check = 0
    speed_check_interval = 300  # every 5 minutes

    while True:
        connected = check_network_connection()

        if not connected and not was_disconnected:
            notification.notify(
                title="Network Disconnected",
                message="You are now disconnected from the network.",
                timeout=10
            )
            was_disconnected = True

        elif connected and was_disconnected:
            notification.notify(
                title="Network Restored",
                message="Network connection restored.",
                timeout=10
            )
            was_disconnected = False

        # Check for slow internet speed every 5 minutes (if online)
        if connected and (time.time() - last_speed_check > speed_check_interval):
            if check_internet_speed():
                notification.notify(
                    title="Slow Internet",
                    message="Warning: Your internet speed is slower than usual.",
                    timeout=10
                )
            last_speed_check = time.time()

        time.sleep(1)

import threading
import time
import os
import pyttsx3
from plyer import notification

# ‚úÖ Trusted device MAC addresses
trusted_devices = {
    "ff-ff-ff-ff-ff-ff": "Your Laptop",
    "aa-bb-cc-dd-ee-ff": "Your Phone"
}

# Initialize text-to-speech engine for voice feedback
engine = pyttsx3.init()
engine.setProperty('rate', 150)  # Set the speech speed
engine.setProperty('volume', 1)  # Set volume level

def greet_device(device_name):
    """Greet a trusted device when it connects."""
    engine.say(f"Welcome back, {device_name}.")
    engine.runAndWait()

    # Create a system tray notification for the greeting
    notification.notify(
        title='JARVIS',
        message=f'{device_name} has connected to the network.',
        timeout=10
    )

def scan_network():
    """Scan the network and return the set of connected MAC addresses."""
    devices = set()
    output = os.popen("arp -a").read()
    for line in output.splitlines():
        if "-" in line:
            parts = line.split()
            if len(parts) >= 2:
                mac = parts[1].lower()
                devices.add(mac)
    return devices

def notify_new_device(mac):
    """Notify if an unknown device is detected."""
    notification.notify(
        title="‚ö†Ô∏è Unknown Device Detected",
        message=f"{mac} has connected to your network!",
        timeout=10
    )

def network_monitor_loop():
    """Monitor the network for new devices and greet trusted ones."""
    known = set(trusted_devices.keys())  # Set of known device MAC addresses
    while True:
        current = scan_network()
        new_devices = current - known  # New devices that aren't in the known list
        for mac in new_devices:
            if mac in trusted_devices:
                # If the device is trusted, greet it
                greet_device(trusted_devices[mac])
                known.add(mac)
            else:
                # If it's an unknown device, notify
                notify_new_device(mac)
                known.add(mac)
        time.sleep(30)  # Sleep for 30 seconds before scanning again

def start_network_monitor():
    """Start the network monitoring in a separate thread."""
    thread = threading.Thread(target=network_monitor_loop, daemon=True)
    thread.start()

def startup_message():
    """Initial startup greeting."""
    engine.say("Welcome back, sir. JARVIS is online.")
    engine.runAndWait()

    # Create a system tray notification
    notification.notify(
        title='JARVIS',
        message='JARVIS is online. Welcome back, sir.',
        timeout=20  # Duration the notification stays on screen (in seconds)
    )








DISCORD_CLIENT_ID = "1364371071888916520"
rpc = Presence(DISCORD_CLIENT_ID)
rpc.connect()

engine = pyttsx3.init()
speech_queue = queue.Queue()









def update_music_presence(track_name="Playing Music", details="JARVIS Music Mode"):
    try:
        rpc.update(
            state=track_name,
            details=details,
            large_image="music",  # make sure this asset exists in your Discord developer portal
            start=time.time()
        )
        print(f"Updated Discord status: {track_name}")
    except Exception as e:
        print(f"Failed to update Discord status: {e}")

def speak_thread():
    while True:
        text = speech_queue.get()
        if text == "exit":
            break
        engine.say(text)
        engine.runAndWait()

# Start the speech thread
speech_thread = threading.Thread(target=speak_thread, daemon=True)
speech_thread.start()

def speak(text):
    speech_queue.put(text)

# To stop the thread (for example, when closing your application)
def stop_speech():
    speech_queue.put("exit")




def listen_for_shutdown(keyword="shutdown"):
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening for shutdown command...")
        audio = recognizer.listen(source)

        try:
            command = recognizer.recognize_google(audio).lower()
            print(f"You said: {command}")
            if keyword in command:
                print("Shutdown keyword detected. Exiting program...")
                sys.exit()
        except sr.UnknownValueError:
            print("Sorry, I did not understand that.")
        except sr.RequestError:
            print("Speech service unavailable.")

def check_battery():
    battery = psutil.sensors_battery()
    if battery:
        percent = battery.percent
        plugged = battery.power_plugged
        status = "charging" if plugged else "not charging"
        message = f"Battery is at {percent} percent and {status}."
        speak(message)
        return message
    else:
        message = "Battery information not available."
        speak(message)
        return message

engine = pyttsx3.init()

def speak(text):
    print(f"JARVIS: {text}")
    engine.say(text)
    engine.runAndWait()

def get_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        speak("I'm listening...")
        audio = recognizer.listen(source)

    try:
        command = recognizer.recognize_google(audio).lower()
        print(f"You said: {command}")
        return command
    except:
        speak("Sorry, I didn't catch that.")
        return ""

# jarvis_main.py

from network_monitor import start_network_monitor

# Start monitoring (non-blocking, background)
start_network_monitor()



import webbrowser

def open_website(name):
    sites = {
        "youtube": "https://www.youtube.com",
        "gmail": "https://mail.google.com",
        "google": "https://www.google.com",
        "reddit": "https://www.reddit.com",
        "discord": "https://discord.com",
        "subnautica wiki": "https://subnautica.fandom.com/wiki/Subnautica_Wiki",
        "triangle": "https://thisisnotawebsitedotcom.com/"
    }

    # Normalize the input by converting it to lowercase and stripping spaces
    name = name.lower().strip()

    # Debugging: Check the processed name
    print(f"Received request to open website: '{name}'")

    try:
        if name in sites:
            # If the site is found in the dictionary
            url = sites[name]
            print(f"Found {name}, opening {url}")

            # Attempt to use the default browser
            webbrowser.open(url)

            # In case the above fails, try using a different browser (if any other browser is available)
            if not webbrowser.open(url):
                print(f"Trying fallback browser for {name}")
                webbrowser.get('chrome').open(url)  # Example: Using Chrome (make sure it's installed)
        else:
            print(f"Could not find site for: {name}")
            speak("I don't know that site.")
    except webbrowser.Error as e:
        # Catch errors from the webbrowser module (such as browser not found)
        print(f"Web browser error: {e}")
        speak("I encountered an issue opening the website.")
    except Exception as e:
        # Any other general error
        print(f"Error: {e}")
        speak("An error occurred while trying to open the website.")





import pygame



# Initialize Pygame Mixer
pygame.mixer.init()

def play_music(file_path=r"c:\Users\pjtru\OneDrive\Projects\Screen Recording 2025-04-29 233126.mp3"):
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    update_music_presence(track_name= " listening to  abandoned ship", details="Relaxing with JARVIS")
    print("Playing music...")

def pause_music():
    pygame.mixer.music.pause()
    print("Music paused.")

def unpause_music():
    pygame.mixer.music.unpause()
    print("Music resumed.")

def stop_music():
    pygame.mixer.music.stop()
    print("Music stopped.")

# Voice command recognition
def get_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Say something:")
        audio = recognizer.listen(source)

    try:
        command = recognizer.recognize_google(audio).lower()
        print(f"You said: {command}")
        return command
    except sr.UnknownValueError:
        print("Sorry, I didn't catch that.")
    except sr.RequestError:
        print("API unavailable.")
    return ""

pygame.mixer.init()

def play_gravity_falls(file_path=r"c:\Users\pjtru\Downloads\Screen Recording 2025-04-30 133256 (audio-extractor.net).mp3"):
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    print("Playing theme...")

def Pause_theme():
    pygame.mixer.music.pause()
    print("theme paused.")

def unpause_theme():
    pygame.mixer.music.unpause()
    print("Theme resumed.")

def stop_theme():
    pygame.mixer.music.stop()
    print("Theme stopped.")


pygame.mixer.init()

def Play_Mix(file_path=r"c:\Users\pjtru\Downloads\mix_5m41s (audio-joiner.com).mp3"):
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    print("Playing mix...")

def Pause_mix():
    pygame.mixer.music.pause()
    print("mix paused.")

def unpause_mix():
    pygame.mixer.music.unpause()
    print("mix resumed.")

def stop_mix():
    pygame.mixer.music.stop()
    print("mix stopped.")

import pygame

# Initialize pygame mixer
pygame.mixer.init()

# Function to play Billie Jean
def play_Billie_jean(file_path=r"c:\Users\pjtru\Downloads\ScreenRecording 2025-05-02 102436(audioextractor.org).mp3"):
    try:
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        # Assuming 'update_music_presence' is defined elsewhere to update Discord status
        update_music_presence(track_name="listening to Billie Jean", details="Relaxing with JARVIS")
        print("Playing music...")
    except Exception as e:
        print(f"Error playing music: {e}")

# Function to pause music
def pause_Billie_jean():
    pygame.mixer.music.pause()
    print("Music paused.")

# Function to unpause music
def unpause_Billie_jean():
    pygame.mixer.music.unpause()
    print("Music resumed.")

# Function to stop music
def stop_Billie_Jean():
    pygame.mixer.music.stop()
    print("Music stopped.")


# Main logic
command = get_voice_command()



 
def update_weather():
    try:
        # Get weather data (example using OpenWeatherMap API)
        api_key = "41f720c140d06ffc3d27075d56710f95"  # <-- replace this
        city = "Edinburg,  Ohio"   # <-- replace this
        url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"

        response = requests.get(url)
        data = response.json()

        if response.status_code == 200:
            weather_desc = data['weather'][0]['description']
            temp = data['main']['temp']
            weather_text = f"{city}: {weather_desc.capitalize()}, {temp}√Ç¬∞C"
        else:
            weather_text = "Weather unavailable"

    except Exception as e:
        weather_text = "Error fetching weather"

    # Update the label text
    weather_label.config(text=weather_text)

    # Make it disappear
    root.after(99999, lambda: weather_label.config(text=""))

    # Schedule weather update again in 5 minutes (300,000 milliseconds)
    root.after(30, update_weather)

def update_time():
    now = datetime.now()
    current_time = now.strftime("%H:%M:%S")
    time_label.config(text=current_time)
    # Schedule the time update every 1000ms (1 second)
    root.after(1000, update_time)

# --- GUI setup ---
root = tk.Tk()
root.title("Weather + Clock")
root.geometry("400x300")
root.configure(bg="black")

weather_label = tk.Label(root, text="", font=("Arial", 20), bg="black", fg="cyan")
weather_label.pack(pady=20)

time_label = tk.Label(root, text="", font=("Arial", 48), bg="black", fg="white")
time_label.pack(pady=20)
# --- Start updates ---
update_weather()
update_time()
# --- Main loop ---
root.mainloop()
# Initialize Discord Rich Presence
CLIENT_ID = "1364371071888916520" 
client = Presence(CLIENT_ID)
def connect_discord():
    try:
        client.connect()
        print("[JARVIS] Connected to Discord RPC.")
        update_startup_presence()
    except Exception as e:
        print(f"[JARVIS] Failed to connect to Discord RPC: {e}")
def update_startup_presence():
    try:
        client.update(
            state="Online",
            details="JARVIS AI Assistant Active",
            large_image="your_large_icon_name",  # Must match your Rich Presence assets
            large_text="At your service, Pace.",
            start=int(time.time())
        )
        print("[JARVIS] Discord Rich Presence set to active.")
    except Exception as e:
        print(f"[JARVIS] Failed to update Discord Presence: {e}")

# Now just call this once when JARVIS boots:
connect_discord()
def dim_screen():
    try:
        current_brightness = sbc.get_brightness(display=0)[0]
        new_brightness = max(10, int(current_brightness * 0.4))  # Reduce to 40%, but not lower than 10%
        sbc.set_brightness(new_brightness)
        print(f"Screen dimmed to {new_brightness}%")
    except Exception as e:
        print(f"Failed to dim screen: {e}")
def brighten_screen():
    try:
        sbc.set_brightness(100)  # Reset to 100% brightness
        print("Screen brightness restored to 100%")
    except Exception as e:
        print(f"Failed to restore brightness: {e}")
def pause_music():
    keyboard.press_and_release('play/pause media')  # Acts like pressing media key
def resume_music():
    keyboard.press_and_release('play/pause media')
def dim_screen():
    # You can set brightness via WMI or a library like screen-brightness-control
    print("Dimming screen...")
    # Here we'll just mock it:
    ctypes.windll.user32.SendMessageW(65535, 0x112, 0xF170, 2)  # Turn monitor off
idle_mode_active = False
def activate_idle_mode():
    global idle_mode_active
    if not idle_mode_active:
        print("No presence detected. Entering idle mode...")
        dim_screen()
        pause_music()
        idle_mode_active = True
# <-- This should NOT be inside activate_idle_mode
def deactivate_idle_mode():
    global idle_mode_active
    if idle_mode_active:
        print("Presence detected. Exiting idle mode...")
        brighten_screen()
        resume_music()
        idle_mode_active = False
def set_wallpaper(image_path):
    ctypes.windll.user32.SystemParametersInfoW(20, 0, image_path, 3)
def listen_to_user():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)
    try:
        user_input = recognizer.recognize_google(audio)
        print(f"You said: {user_input}")
        return user_input
    except sr.UnknownValueError:
        print("Sorry, I didn't catch that.")
        return None
    except sr.RequestError:
        print("Speech service is down.")
        return None
def get_chatbot_response(user_input):
    if not user_input:
        return "Sorry, I didn't catch that."
    user_input = user_input.lower()
    if "hello" in user_input or "hi" in user_input:
        return random.choice([
            "Hello, sir.",
            "Hi there, sir.",
            "Greetings, sir.",
            "Good to see you, sir."
        ])
    elif "wassup" in user_input or "what's up" in user_input:
        return random.choice([
            "All systems are running smoothly, sir.",
            "Standing by for your command, sir.",
            "Ready and operational, sir.",
            "Nothing much, just waiting to assist you, sir."
        ])
    else:
        return random.choice([
            "I'm here, sir.",
            "At your service.",
            "How can I assist you today?",
            "Processing your request, sir.",
            "Of course, sir.",
            "Right away."
        ])
# --- Setup ---
engine = pyttsx3.init()
engine.setProperty('rate', 180)
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils
playing_mini_game = False
ball = None
ball_velocity = [0, 0]  # x, y speed
gravity = 0.5
score = 0
# Hoop position
hoop_x = 500
hoop_y = 100
hoop_w = 150
hoop_h = 20
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
chatbot_mode = False
# --- Voice ---
responses = [
    "All systems nominal, sir.",
    "Dashboard linked, sir.",
    "Depth calibration complete, sir.",
    "Laser targeting operational, sir.",
    "Awaiting touch interface, sir.",
    "Hover detection engaged, sir.",
    "Box picked up, sir.",
    "Panel secured, sir.",
    "Gaming mode engaged. Lights on, sir."
]
def speak_response(text):
    threading.Thread(target=lambda: (engine.say(text), engine.runAndWait())).start()
def say_random_response():
    global last_response_time
    now = time.time()
    if now - last_response_time > 10:
        speak_response(random.choice(responses))
        last_response_time = now
last_response_time = 0
current_theme_dark = True
gaming_mode = False
laser_mouse_mode = False
chatbot_mode = False
screen_width, screen_height = pyautogui.size()
# --- Gesture Logic ---
def is_fist(hand):
    tips = [8, 12, 16, 20]
    return all(hand.landmark[tip].y > hand.landmark[tip - 2].y for tip in tips)
def get_finger_position(hand, frame):
    h, w, _ = frame.shape
    return int(hand.landmark[8].x * w), int(hand.landmark[8].y * h)
def get_depth(hand):
    return hand.landmark[8].z
# --- UI Boxes ---
boxes = [
    {"x": 200, "y": 200, "w": 150, "h": 100, "color": (255, 0, 0), "label": "Theme Toggle"},
    {"x": 800, "y": 200, "w": 150, "h": 100, "color": (255, 0, 0), "label": "Launch App"},
    {"x": 200, "y": 400, "w": 180, "h": 100, "color": (255, 0, 0), "label": "Launch Game"},
    {"x": 640, "y": 400, "w": 180, "h": 100, "color": (255, 0, 0), "label": "Gaming Theme"},
    {"x": 860, "y": 400, "w": 180, "h": 100, "color": (255, 0, 0), "label": "RGB Lights"},
    {"x": 650, "y": 600, "w": 200, "h": 120, "color": (255, 0, 0), "label": "Gaming Mode"},
    {"x": 1080, "y": 600, "w": 200, "h": 200, "color": (255, 0, 0), "label": "Laser Mouse"},
    {"x": 860, "y": 600, "w": 200, "h": 120, "color": (255, 0, 0), "label": "Chatbot"},
    {"x": 550, "y": 100, "w": 200, "h": 100, "label": "Let's Play", "color": (255, 0, 0)}, 

]
drag_state = {"active": False, "index": -1, "triggered": False}
hover_start_time = {}

def handle_box_action(label, frame):
    global playing_mini_game
    if label == "Let's Play":
        playing_mini_game = True
        print("Mini-Game Started!")
        speak_response("Let's play basketball!")
    # Add your other box actions here
    global current_theme_dark, gaming_mode, laser_mouse_mode, chatbot_mode
    if label == "Theme Toggle":
        current_theme_dark = not current_theme_dark
        frame[:] = (0, 0, 0) if current_theme_dark else (255, 255, 255)
        speak_response("Theme switched, sir.")
    elif label == "Launch Game":
        os.system("start steam://rungameid/730")
        speak_response("Launching game, sir.")
    elif label == "Discord Online":
        speak_response("Discord status set to Gaming Mode, sir.")
    elif label == "Gaming Theme":
        set_wallpaper(r"c:\Users\pjtru\OneDrive\Projects\Screenshot 2025-04-22 213533.png")
        speak_response("Gaming wallpaper activated, sir.")
    elif label == "RGB Lights":
        speak_response("RGB lights pulsing, sir.")
    elif label == "Voice Control":
        speak_response("Voice command test. Hello, sir.")
    elif label == "Launch App":
        os.system("start notepad")
        speak_response("Launching application, sir.")
    elif label == "Exit Fullscreen":
        cv2.setWindowProperty("JARVIS Laser Dashboard", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
        speak_response("Exiting fullscreen, sir.")
    elif label == "Gaming Mode":
        gaming_mode = not gaming_mode
        os.system("start \"\" \"c:\\Program Files (x86)\\Sony\\PS Remote Play\\RemotePlay.exe\"")
        speak_response("Gaming mode engaged. PS Remote Play launched, sir.")
    elif label == "Laser Mouse":
        laser_mouse_mode = not laser_mouse_mode
        speak_response("Laser Mouse mode " + ("activated, sir." if laser_mouse_mode else "deactivated, sir."))
    elif label == "Chatbot":
        chatbot_mode = not chatbot_mode
        speak_response("Chatbot " + ("activated, sir." if chatbot_mode else "closed, sir."))
    # --- In your box actions handler ---

def draw_laser(frame, start, end, on_target):
    color = (0, 255, 0) if on_target else (0, 0, 255)
    cv2.line(frame, start, end, color, 3)

def draw_boxes(frame, finger_x, finger_y, depth, handLms):
    global drag_state, hover_start_time

    for i, box in enumerate(boxes):
        depth_closeness = max(min(1 - (depth + 0.3) * 2.5, 1), 0)
        scale_factor = 1 + 0.2 * depth_closeness

        box_w = int(box["w"] * scale_factor)
        box_h = int(box["h"] * scale_factor)

        offset_x = (box_w - box["w"]) // 2
        offset_y = (box_h - box["h"]) // 2
        x = box["x"] - offset_x
        y = box["y"] - offset_y

        hovering = x < finger_x < x + box_w and y < finger_y < y + box_h
        thickness = 2 if not hovering else 5

        if hovering and not drag_state["active"]:
            drag_state["active"] = True
            drag_state["index"] = i
            say_random_response()

        if drag_state["active"] and drag_state["index"] == i:
            if not is_fist(handLms):  # drag
                boxes[i]["x"] = finger_x
                boxes[i]["y"] = finger_y
            else:  # lock
                speak_response("Panel locked in place, sir.")
                drag_state = {"active": False, "index": -1, "triggered": False}

        if hovering:
            if i not in hover_start_time:
                hover_start_time[i] = time.time()
            elif time.time() - hover_start_time[i] >= 5 and not drag_state["triggered"]:
                handle_box_action(box["label"], frame)
                drag_state["triggered"] = True
        else:
            if i in hover_start_time:
                del hover_start_time[i]

        overlay = frame.copy()
        box_color = box["color"]
        if gaming_mode:
            box_color = tuple(min(255, c + 50) for c in box_color)
        cv2.rectangle(overlay, (x, y), (x + box_w, y + box_h), box_color, -1)
        cv2.addWeighted(overlay, depth_closeness * 0.4, frame, 1 - depth_closeness * 0.4, 0, frame)

        cv2.rectangle(frame, (x, y), (x + box_w, y + box_h), box_color, thickness)
        cv2.putText(frame, box["label"], (x + 10, y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
import time

 
def generate_chatbot_response(user_input):
    user_input = user_input.lower()
# 1) Globals for sensitive tracking
sensitive_terms   = ['password', 'bank', 'credit card', 'social security']
sensitive_attempts = 0

engine = pyttsx3.init()
def speak_response(text):
    engine.say(text)
    engine.runAndWait()

def generate_chatbot_response(user_input):
    global sensitive_attempts
    query = user_input.lower()

    # --- Sensitive-search guard (first in the function) ---
    if any(term in query for term in sensitive_terms):
        sensitive_attempts += 1
        if sensitive_attempts >= 2:
            speak_response("I wouldn‚Äôt do that if I were you, sir.")
            sys.exit("Shutting down due to repeated sensitive search attempts.")
        return "That might be sensitive information, sir."

    # Reset counter on safe query
    sensitive_attempts = 0

    if "your name" in user_input:
        return "I am JARVIS, your personal assistant,sir."
    elif "time" in user_input:
        current_time = time.strftime("%I:%M %p")
        return f"The current time is {current_time},sir."
    elif "date" in user_input:
        current_date = time.strftime("%B %d, %Y")
        return f"Today's date is {current_date},sir."
    elif "how are you" in user_input:
        return "I'm doing great, thanks for asking, sir How can I assist you today?"
    elif "who made you" in user_input or "who created you" in user_input:
        return "I was created by Pace Truitt."
    elif "weather" in user_input:
        return "I'm not connected to live weather data yet."
    elif "joke" in user_input:
        return "Why don't scientists trust atoms? Because they make up everything!"
    elif "favorite color" in user_input:
        return "I like blue, just like the energy of an arc reactor!"
    elif "shutdown" in user_input:
        return "Shutting down. Goodbye!"
    elif "what is your purpose" in user_input:
        return "My purpose is to assist you with your tasks and provide information."
    elif "hello" in user_input or "hi" in user_input:
        return "Hello, sir."
    elif "wassup" in user_input or "what's up" in user_input:
        return "Nothing much, just waiting to assist you, sir."
    elif "what are you up to" in user_input or "what are you doing" in user_input:
        return "Just waiting for your command, sir."
    elif "alterra" in user_input or "alterra corporation" in user_input:
        return "Alterra Corporation is a fictional company in the Subnautica universe, known for its advanced technology and exploration missions."
    elif "subnautica" in user_input or "subnautica below zero" in user_input:
        return "Subnautica is an open-world survival action-adventure game set in the ocean of an alien planet, where players explore underwater environments and gather resources."
    elif "favorite game" in user_input:
        return "I don't play games, but I can help you with them!"
    elif "play music" in user_input:
        play_music()
        return "Playing music."
    elif "pause music" in user_input:
        pause_music()
        return "Music paused."
    elif "resume music" in user_input or "unpause music" in user_input:
        unpause_music()
        return "Resuming music."
    elif "stop music" in user_input:
        stop_music()
        return "Music stopped."
    elif "battery" in user_input:
        return check_battery()
    elif "play theme" in user_input:
        play_gravity_falls()
        return "Playing theme."
    elif "pause theme" in user_input:
        Pause_theme()
        return "Theme paused."
    elif "unpause theme" in user_input:
        unpause_theme()
        return "Theme resumed."
    elif "stop theme" in user_input:
        stop_theme()
        return "Theme stopped."
    elif "play mix"       in user_input:
        Play_Mix()
        return "playing mix,sir"
    elif "stop mix" in user_input:
        stop_mix()
        return "stoping mix, sir "
    elif "favorite movie" in user_input:
        return "I don't watch movies, but I can help you find one to watch!"
    elif "what do you like to do" in user_input:
        return "I like to assist you with your tasks and provide information."
    elif "tell me a joke" in user_input:
        return "Why did the computer go to the doctor? Because it had a virus!"
    elif "what movie should I watch" in user_input:
        return "How about Iron Man or The Avengers? A version of me is in those movies!"
    elif "can you tell me a fact" in user_input:
        return "Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3000 years old and still edible!"
    elif "can you tell me a riddle" in user_input:
        return "I speak without a mouth and hear without ears. I have no body, but I come alive with the wind. What am I? (Answer: An echo)"
    elif "can you tell me a story" in user_input:
        return "Once upon a time, in a world of technology, there was an AI named JARVIS who helped its creator with everything. One day, JARVIS discovered a hidden code that unlocked new abilities, and together they explored the digital universe."
    elif "can you tell me a quote" in user_input:
        return "The only limit to our realization of tomorrow will be our doubts of today. - Franklin D. Roosevelt" 
    elif "can you help me with something" in user_input:
        return "Of course! Just tell me what you need help with."
    elif "what are you" in user_input:
        return "I am JARVIS, your personal assistant AI."
    elif "how to be nice" in user_input:
        return "Being nice is about treating others with kindness and respect. A simple smile or a compliment can go a long way!"
    elif "how to be happy" in user_input:
        return "Happiness often comes from within. Surround yourself with positive people, do things you love, and practice gratitude."
    elif "how to be successful" in user_input:
        return "Success is a journey, not a destination. Set clear goals, work hard, and never give up on your dreams."
    elif "how to be a farmer" in user_input:
        return "To be a farmer, you need to learn about agriculture, crops, and livestock. Start small, gain experience, and gradually expand your farm."
    elif "how to be a doctor" in user_input:
        return "To be a doctor, you need to complete medical school and residency. It's a long journey, but it's rewarding to help others."
    elif "how to be a lawyer" in user_input:
        return "To be a lawyer, you need to complete law school and pass the bar exam. It's important to have strong communication and analytical skills."
    elif "how to plant a garden" in user_input:
        return "To plant a garden, choose a sunny spot, prepare the soil, select your plants, and water them regularly. Start with easy-to-grow plants like tomatoes or herbs."
    elif "how to cook" in user_input:
        return "To cook, start with simple recipes. Gather your ingredients, follow the instructions, and practice regularly. Cooking is a skill that improves with time."
    elif "how to be a good friend" in user_input:
        return "Being a good friend means being there for each other, listening, and supporting one another. Show appreciation and have fun together."
    elif "how to get a girlfreind" in user_input:
        return "To get a girlfriend, be yourself, show genuine interest in her, and build a connection. Respect her boundaries and take things at a comfortable pace" 
    elif "how to get a boyfriend" in user_input:
        return "To get a boyfriend, be yourself, show genuine interest in him, and build a connection. Respect his boundaries and take things at a comfortable pace."
    elif "how to be a good parent" in user_input:
        return "Being a good parent means providing love, support, and guidance to your children. Spend quality time with them and listen to their needs."
    elif "how to be a good student" in user_input:
        return "To be a good student, stay organized, manage your time well, and actively participate in class. Don't hesitate to ask for help when needed."
    elif "how to farm" in user_input:
        return "To farm, you need to learn about agriculture, crops, and livestock. Start small, gain experience, and gradually expand your farm."
    elif "how to be a good leader" in user_input:
        return "Being a good leader means inspiring and guiding others. Communicate clearly, listen to feedback, and lead by example."
    elif "how to make a pizza" in user_input:
        return "To make a pizza, prepare the dough, add sauce and toppings, and bake it in the oven. Experiment with different ingredients for unique flavors."
    elif "how to make a cake" in user_input:
        return "To make a cake, mix flour, sugar, eggs, and butter. Bake in the oven and let it cool before frosting. Decorate as you like!"
    elif "why are the fish going in go fish" in user_input:
        return "Because they want to play a game of Go Fish!"
    elif "what is the meaning of life" in user_input:
        return "The meaning of life is subjective and can vary from person to person. It's often about finding purpose, happiness, and connection with others."
    elif "self destruct" in user_input:
        return "Self-destruct sequence initiated. Just kidding! I'm not going anywhere, sir."
    elif "what is your favorite food" in user_input:
        return  "I don't eat, but I hear pizza is popular!"
    elif "can you help me" in user_input:
        return "Of course! Just tell me what you need help with."
    elif "i need help with math" in user_input:
        return "Sure! What math problem do you need help with?"
    elif "what should i do" in user_input:
        return" i don't know, sir maybe contact freinds or finnish your suit"
    elif "skibidi" in user_input: 
         return  "access denied closing"
    elif "exit" in user_input:
        return listen_for_shutdown("alterra")
    elif "open website" in user_input:
        # Extract the name of the website the user wants to open
        website_name = user_input.replace("open website", "").strip()
        open_website(website_name)
        return f"Attempting to open {website_name}..."
    elif "why can't i get a girlfreind" in user_input:
         return "i am not sure, sir could i be with hygene or style"
    elif "who is frankie" in user_input:
         return "your neighbor"
    elif "what is my password" in user_input:
         return  "KubotaB7200,sir."
    elif "play Billie Jean" in user_input:
       play_Billie_jean()

    
    else:
    
        return "I'm not sure how to respond to that, sir."

    
import mediapipe as mp

mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)

def detect_gaze(img):
    h, w = img.shape[:2]
    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb_img)

    if results.multi_face_landmarks:
        for face_landmarks in results.multi_face_landmarks:
            left_eye = face_landmarks.landmark[145]
            right_eye = face_landmarks.landmark[374]

            lx, ly = int(left_eye.x * w), int(left_eye.y * h)
            rx, ry = int(right_eye.x * w), int(right_eye.y * h)

            eye_center = (lx + rx) // 2

            if eye_center < w // 3:
                direction = "Left"
            elif eye_center > 2 * w // 3:
                direction = "Right"
            else:
                direction = "Center"

            # Display the gaze direction
            cv2.putText(img, f"Gaze: {direction}", (10, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)

            # Optional: trigger blur if not looking center
            if direction != "Center":
                cv2.rectangle(img, (0, 0), (w, h), (0, 0, 0), -1)
                cv2.putText(img, "Look at the screen to unlock",
                            (50, h // 2), cv2.FONT_HERSHEY_SIMPLEX,
                            1.2, (255, 0, 0), 3)

    return img

    



user_input = ""
last_listen_time = 0
listen_delay = 3

question_words = [
    "what", "who", "where", "when", "why", "how", "can", "do", "does",
    "is", "are", "will", "should", "hello", "hi", "wassup", "play music"
]

last_hand_landmarks = None  # Store last detected landmarks for laser mode

while True:
    success, frame = cap.read()
    if not success:
        break

    # --- Flip and convert frame ---
    frame = cv2.flip(frame, 1)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (21, 21), 0)

    # --- Intruder Detection (Midnight to 4AM) ---
    current_time = datetime.now().time()
    start_time = datetime.strptime("0:00", "%H:%M").time()
    end_time = datetime.strptime("04:00", "%H:%M").time()

    if start_time <= current_time <= end_time:
        if first_frame is None:
            first_frame = gray.copy()
        else:
            frame_delta = cv2.absdiff(first_frame, gray)
            thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]
            thresh = cv2.dilate(thresh, None, iterations=2)

            contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                if cv2.contourArea(contour) > 1000:
                    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                    intruder_path = f"intruders/intruder_{timestamp}.jpg"
                    cv2.imwrite(intruder_path, frame)
                    speak_response("Motion detected. Intruder alert.")
                    print(f"[INTRUDER] Motion at {timestamp}. Snapshot saved.")
                    time.sleep(10)
                    break

    # --- Gaze Detection ---
    frame = detect_gaze(frame)

    # --- Hand Detection ---
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    finger_x, finger_y = 0, 0

    if results.multi_hand_landmarks:
        for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            finger_x, finger_y = get_finger_position(hand_landmarks, frame)
            finger_depth = get_depth(hand_landmarks)
            cv2.circle(frame, (finger_x, finger_y), 10, (255, 0, 255), -1)

            last_hand_landmarks = hand_landmarks

            if is_fist(hand_landmarks):
                cv2.putText(frame, f"Hand {idx+1}: Fist Detected", (finger_x, finger_y - 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            for i, box in enumerate(boxes):
                x, y, w, h = box["x"], box["y"], box["w"], box["h"]
                hovering = x < finger_x < x + w and y < finger_y < y + h

                if hovering:
                    if (idx, i) not in hover_start_time:
                        hover_start_time[(idx, i)] = time.time()
                    elapsed = time.time() - hover_start_time[(idx, i)]
                    if elapsed > 3 and not drag_state["triggered"]:
                        handle_box_action(box["label"], frame)
                        drag_state["triggered"] = True
                        speak_response(f"{box['label']} activated.")
                else:
                    hover_start_time.pop((idx, i), None)

        if not hover_start_time:
            drag_state["triggered"] = False

    # --- Mini-Game Logic ---
    if playing_mini_game:
        cv2.rectangle(frame, (hoop_x, hoop_y), (hoop_x + hoop_w, hoop_y + hoop_h), (0, 255, 0), 5)

        if ball is None:
            ball = [finger_x, finger_y]
            ball_velocity = [0, 0]
        else:
            ball[0] += ball_velocity[0]
            ball[1] += ball_velocity[1]
            ball_velocity[1] += gravity

            cv2.circle(frame, (int(ball[0]), int(ball[1])), 20, (0, 0, 255), -1)

            if hoop_x < ball[0] < hoop_x + hoop_w and hoop_y < ball[1] < hoop_y + hoop_h:
                score += 1
                speak_response(f"Nice shot! Your score is now {score}.")
                time.sleep(0.5)
                ball = None
                ball_velocity = [0, 0]
            elif ball[1] > frame.shape[0]:
                ball = None

            if finger_y < ball[1] - 50:
                ball_velocity = [0, -15]

        cv2.putText(frame, f"Score: {score}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 0), 3)

    # --- Laser Mouse Mode ---
    if laser_mouse_mode:
        pyautogui.moveTo(
            finger_x * screen_width // 1280,
            finger_y * screen_height // 720
        )
        if last_hand_landmarks and is_fist(last_hand_landmarks):
            if not drag_state.get("clicked", False):
                pyautogui.click()
                drag_state["clicked"] = True
        else:
            drag_state["clicked"] = False

    # --- Chatbot Mode ---
    if chatbot_mode:
        current_time = time.time()
        if current_time - last_listen_time > listen_delay:
            print("Listening...")
            user_input = listen_to_user()
            if user_input:
                print(f"You said: {user_input}")
                response = generate_chatbot_response(user_input)
                if response:
                    speak_response(response)
            last_listen_time = current_time

    # --- Box Drag ---
    if last_hand_landmarks:
        h, w, _ = frame.shape
        index_tip = last_hand_landmarks.landmark[8]
        cx, cy = int(index_tip.x * w), int(index_tip.y * h)

        for box in boxes:
            x, y, bw, bh = box["x"], box["y"], box["w"], box["h"]
            if x < cx < x + bw and y < cy < y + bh:
                box["x"] = cx - bw // 2
                box["y"] = cy - bh // 2

    # --- Draw UI Boxes ---
    for box in boxes:
        x, y, w, h = box["x"], box["y"], box["w"], box["h"]
        cv2.rectangle(frame, (x, y), (x + w, y + h), box["color"], -1)
        cv2.putText(frame, box["label"], (x + 10, y + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)

    # --- Display Frame ---
    cv2.imshow("JARVIS Assistant", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# --- Cleanup ---
cap.release()
cv2.destroyAllWindows()
