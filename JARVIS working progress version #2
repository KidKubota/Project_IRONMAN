import cv2
import mediapipe as mp
import pyttsx3
import os
import time
import threading
import pyautogui
import random
import speech_recognition as sr
import time
import ctypes
import pyttsx3 
import ctypes 
import keyboard
import screen_brightness_control as sbc
from pypresence import Presence
import time
import requests
import random
import tkinter as tk

import requests
import os
import time
import cv2
import cv2
from datetime import datetime
import threading

import os
import requests
from spotipy.oauth2 import SpotifyOAuth
import time
import threading
import speech_recognition as sr
from playsound import playsound
import psutil
import webbrowser
import speech_recognition as sr
import pyttsx3

engine = pyttsx3.init()

def speak(text):
    print(f"JARVIS: {text}")
    engine.say(text)
    engine.runAndWait()

def get_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        speak("I'm listening...")
        audio = recognizer.listen(source)

    try:
        command = recognizer.recognize_google(audio).lower()
        print(f"You said: {command}")
        return command
    except:
        speak("Sorry, I didn't catch that.")
        return ""

def check_battery():
    battery = psutil.sensors_battery()
    if battery:
        percent = battery.percent
        plugged = battery.power_plugged
        status = "charging" if plugged else "not charging"
        speak(f"Battery is at {percent} percent and {status}.")
    else:
        speak("Battery information not available.")

def open_website(name):
    sites = {
        "youtube": "https://www.youtube.com",
        "gmail": "https://mail.google.com",
        "google": "https://www.google.com",
        "reddit": "https://www.reddit.com"
    }
    if name in sites:
        speak(f"Opening {name}")
        webbrowser.open(sites[name])
    else:
        speak("I don't know that site.")

def set_alarm(alarm_time_str):
    alarm_time = datetime.datetime.strptime(alarm_time_str, "%H:%M").time()
    print(f"Alarm set for {alarm_time.strftime('%I:%M %p')}")

    def alarm_thread():
        while True:
            now = datetime.datetime.now().time()
            if now.hour == alarm_time.hour and now.minute == alarm_time.minute:
                print("⏰ Alarm ringing!")
                playsound("alarm.mp3")  # Make sure alarm.mp3 is in the same folder
                break
            time.sleep(30)

    threading.Thread(target=alarm_thread, daemon=True).start()

def get_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Say an alarm time (e.g., 'set alarm for 7 30')")
        audio = recognizer.listen(source)

    try:
        command = recognizer.recognize_google(audio).lower()
        print(f"You said: {command}")
        return command
    except:
        return ""

def parse_alarm_command(command):
    if "set alarm for" in command:
        try:
            words = command.replace("set alarm for", "").strip().split()
            hour = int(words[0])
            minute = int(words[1]) if len(words) > 1 else 0
            set_alarm(f"{hour:02d}:{minute:02d}")
        except:
            print("Could not understand time format.")



import pygame
import speech_recognition as sr

# Initialize Pygame Mixer
pygame.mixer.init()

def play_music(file_path=r"c:\Users\pjtru\OneDrive\Projects\Screen Recording 2025-04-29 233126.mp3"):
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    print("Playing music...")

def pause_music():
    pygame.mixer.music.pause()
    print("Music paused.")

def unpause_music():
    pygame.mixer.music.unpause()
    print("Music resumed.")

def stop_music():
    pygame.mixer.music.stop()
    print("Music stopped.")

# Voice command recognition
def get_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Say something:")
        audio = recognizer.listen(source)

    try:
        command = recognizer.recognize_google(audio).lower()
        print(f"You said: {command}")
        return command
    except sr.UnknownValueError:
        print("Sorry, I didn't catch that.")
    except sr.RequestError:
        print("API unavailable.")
    return ""

# Main logic
command = get_voice_command()



 
def update_weather():
    try:
        # Get weather data (example using OpenWeatherMap API)
        api_key = "41f720c140d06ffc3d27075d56710f95"  # <-- replace this
        city = "Edinburg,  Ohio"   # <-- replace this
        url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"

        response = requests.get(url)
        data = response.json()

        if response.status_code == 200:
            weather_desc = data['weather'][0]['description']
            temp = data['main']['temp']
            weather_text = f"{city}: {weather_desc.capitalize()}, {temp}Â°C"
        else:
            weather_text = "Weather unavailable"

    except Exception as e:
        weather_text = "Error fetching weather"

    # Update the label text
    weather_label.config(text=weather_text)

    # Make it disappear after 7.3 seconds
    root.after(7300, lambda: weather_label.config(text=""))

    # Schedule weather update again in 5 minutes (300,000 milliseconds)
    root.after(300000, update_weather)

def update_time():
    now = datetime.now()
    current_time = now.strftime("%H:%M:%S")
    time_label.config(text=current_time)
    # Schedule the time update every 1000ms (1 second)
    root.after(1000, update_time)

# --- GUI setup ---
root = tk.Tk()
root.title("Weather + Clock")
root.geometry("400x300")
root.configure(bg="black")

weather_label = tk.Label(root, text="", font=("Arial", 20), bg="black", fg="cyan")
weather_label.pack(pady=20)

time_label = tk.Label(root, text="", font=("Arial", 48), bg="black", fg="white")
time_label.pack(pady=20)
# --- Start updates ---
update_weather()
update_time()
# --- Main loop ---
root.mainloop()
# Initialize Discord Rich Presence
CLIENT_ID = "1364371071888916520" 
client = Presence(CLIENT_ID)
def connect_discord():
    try:
        client.connect()
        print("[JARVIS] Connected to Discord RPC.")
        update_startup_presence()
    except Exception as e:
        print(f"[JARVIS] Failed to connect to Discord RPC: {e}")
def update_startup_presence():
    try:
        client.update(
            state="Online",
            details="JARVIS AI Assistant Active",
            large_image="your_large_icon_name",  # Must match your Rich Presence assets
            large_text="At your service, Pace.",
            start=int(time.time())
        )
        print("[JARVIS] Discord Rich Presence set to active.")
    except Exception as e:
        print(f"[JARVIS] Failed to update Discord Presence: {e}")

# Now just call this once when JARVIS boots:
connect_discord()
def dim_screen():
    try:
        current_brightness = sbc.get_brightness(display=0)[0]
        new_brightness = max(10, int(current_brightness * 0.4))  # Reduce to 40%, but not lower than 10%
        sbc.set_brightness(new_brightness)
        print(f"Screen dimmed to {new_brightness}%")
    except Exception as e:
        print(f"Failed to dim screen: {e}")
def brighten_screen():
    try:
        sbc.set_brightness(100)  # Reset to 100% brightness
        print("Screen brightness restored to 100%")
    except Exception as e:
        print(f"Failed to restore brightness: {e}")
def pause_music():
    keyboard.press_and_release('play/pause media')  # Acts like pressing media key
def resume_music():
    keyboard.press_and_release('play/pause media')
def dim_screen():
    # You can set brightness via WMI or a library like screen-brightness-control
    print("Dimming screen...")
    # Here we'll just mock it:
    ctypes.windll.user32.SendMessageW(65535, 0x112, 0xF170, 2)  # Turn monitor off
idle_mode_active = False
def activate_idle_mode():
    global idle_mode_active
    if not idle_mode_active:
        print("No presence detected. Entering idle mode...")
        dim_screen()
        pause_music()
        idle_mode_active = True
# <-- This should NOT be inside activate_idle_mode
def deactivate_idle_mode():
    global idle_mode_active
    if idle_mode_active:
        print("Presence detected. Exiting idle mode...")
        brighten_screen()
        resume_music()
        idle_mode_active = False
def set_wallpaper(image_path):
    ctypes.windll.user32.SystemParametersInfoW(20, 0, image_path, 3)
def listen_to_user():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)
    try:
        user_input = recognizer.recognize_google(audio)
        print(f"You said: {user_input}")
        return user_input
    except sr.UnknownValueError:
        print("Sorry, I didn't catch that.")
        return None
    except sr.RequestError:
        print("Speech service is down.")
        return None
def get_chatbot_response(user_input):
    if not user_input:
        return "Sorry, I didn't catch that."
    user_input = user_input.lower()
    if "hello" in user_input or "hi" in user_input:
        return random.choice([
            "Hello, sir.",
            "Hi there, sir.",
            "Greetings, sir.",
            "Good to see you, sir."
        ])
    elif "wassup" in user_input or "what's up" in user_input:
        return random.choice([
            "All systems are running smoothly, sir.",
            "Standing by for your command, sir.",
            "Ready and operational, sir.",
            "Nothing much, just waiting to assist you, sir."
        ])
    else:
        return random.choice([
            "I'm here, sir.",
            "At your service.",
            "How can I assist you today?",
            "Processing your request, sir.",
            "Of course, sir.",
            "Right away."
        ])
# --- Setup ---
engine = pyttsx3.init()
engine.setProperty('rate', 180)
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils
playing_mini_game = False
ball = None
ball_velocity = [0, 0]  # x, y speed
gravity = 0.5
score = 0
# Hoop position
hoop_x = 500
hoop_y = 100
hoop_w = 150
hoop_h = 20
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
chatbot_mode = False
# --- Voice ---
responses = [
    "All systems nominal, sir.",
    "Dashboard linked, sir.",
    "Depth calibration complete, sir.",
    "Laser targeting operational, sir.",
    "Awaiting touch interface, sir.",
    "Hover detection engaged, sir.",
    "Box picked up, sir.",
    "Panel secured, sir.",
    "Gaming mode engaged. Lights on, sir."
]
def speak_response(text):
    threading.Thread(target=lambda: (engine.say(text), engine.runAndWait())).start()
def say_random_response():
    global last_response_time
    now = time.time()
    if now - last_response_time > 10:
        speak_response(random.choice(responses))
        last_response_time = now
last_response_time = 0
current_theme_dark = True
gaming_mode = False
laser_mouse_mode = False
chatbot_mode = False
screen_width, screen_height = pyautogui.size()
# --- Gesture Logic ---
def is_fist(hand):
    tips = [8, 12, 16, 20]
    return all(hand.landmark[tip].y > hand.landmark[tip - 2].y for tip in tips)
def get_finger_position(hand, frame):
    h, w, _ = frame.shape
    return int(hand.landmark[8].x * w), int(hand.landmark[8].y * h)
def get_depth(hand):
    return hand.landmark[8].z
# --- UI Boxes ---
boxes = [
    {"x": 200, "y": 200, "w": 150, "h": 100, "color": (0, 255, 255), "label": "Theme Toggle"},
    {"x": 800, "y": 200, "w": 150, "h": 100, "color": (100, 200, 255), "label": "Launch App"},
    {"x": 200, "y": 400, "w": 180, "h": 100, "color": (0, 200, 255), "label": "Launch Game"},
    {"x": 640, "y": 400, "w": 180, "h": 100, "color": (255, 180, 50), "label": "Gaming Theme"},
    {"x": 860, "y": 400, "w": 180, "h": 100, "color": (0, 255, 100), "label": "RGB Lights"},
    {"x": 650, "y": 600, "w": 200, "h": 120, "color": (255, 0, 200), "label": "Gaming Mode"},
    {"x": 1080, "y": 600, "w": 200, "h": 200, "color": (100, 100, 255), "label": "Laser Mouse"},
    {"x": 860, "y": 600, "w": 200, "h": 120, "color": (200, 100, 255), "label": "Chatbot"},
    {"x": 550, "y": 100, "w": 200, "h": 100, "label": "Let's Play", "color": (255, 0, 0)}, 

]
drag_state = {"active": False, "index": -1, "triggered": False}
hover_start_time = {}

def handle_box_action(label, frame):
    global playing_mini_game
    if label == "Let's Play":
        playing_mini_game = True
        print("Mini-Game Started!")
        speak_response("Let's play basketball!")
    # Add your other box actions here
    global current_theme_dark, gaming_mode, laser_mouse_mode, chatbot_mode
    if label == "Theme Toggle":
        current_theme_dark = not current_theme_dark
        frame[:] = (0, 0, 0) if current_theme_dark else (255, 255, 255)
        speak_response("Theme switched, sir.")
    elif label == "Launch Game":
        os.system("start steam://rungameid/730")
        speak_response("Launching game, sir.")
    elif label == "Discord Online":
        speak_response("Discord status set to Gaming Mode, sir.")
    elif label == "Gaming Theme":
        set_wallpaper(r"c:\Users\pjtru\OneDrive\Projects\Screenshot 2025-04-22 213533.png")
        speak_response("Gaming wallpaper activated, sir.")
    elif label == "RGB Lights":
        speak_response("RGB lights pulsing, sir.")
    elif label == "Voice Control":
        speak_response("Voice command test. Hello, sir.")
    elif label == "Launch App":
        os.system("start notepad")
        speak_response("Launching application, sir.")
    elif label == "Exit Fullscreen":
        cv2.setWindowProperty("JARVIS Laser Dashboard", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
        speak_response("Exiting fullscreen, sir.")
    elif label == "Gaming Mode":
        gaming_mode = not gaming_mode
        os.system("start \"\" \"c:\\Program Files (x86)\\Sony\\PS Remote Play\\RemotePlay.exe\"")
        speak_response("Gaming mode engaged. PS Remote Play launched, sir.")
    elif label == "Laser Mouse":
        laser_mouse_mode = not laser_mouse_mode
        speak_response("Laser Mouse mode " + ("activated, sir." if laser_mouse_mode else "deactivated, sir."))
    elif label == "Chatbot":
        chatbot_mode = not chatbot_mode
        speak_response("Chatbot " + ("activated, sir." if chatbot_mode else "closed, sir."))
    # --- In your box actions handler ---

def draw_laser(frame, start, end, on_target):
    color = (0, 255, 0) if on_target else (0, 0, 255)
    cv2.line(frame, start, end, color, 3)

def draw_boxes(frame, finger_x, finger_y, depth, handLms):
    global drag_state, hover_start_time

    for i, box in enumerate(boxes):
        depth_closeness = max(min(1 - (depth + 0.3) * 2.5, 1), 0)
        scale_factor = 1 + 0.2 * depth_closeness

        box_w = int(box["w"] * scale_factor)
        box_h = int(box["h"] * scale_factor)

        offset_x = (box_w - box["w"]) // 2
        offset_y = (box_h - box["h"]) // 2
        x = box["x"] - offset_x
        y = box["y"] - offset_y

        hovering = x < finger_x < x + box_w and y < finger_y < y + box_h
        thickness = 2 if not hovering else 5

        if hovering and not drag_state["active"]:
            drag_state["active"] = True
            drag_state["index"] = i
            say_random_response()

        if drag_state["active"] and drag_state["index"] == i:
            if not is_fist(handLms):  # drag
                boxes[i]["x"] = finger_x
                boxes[i]["y"] = finger_y
            else:  # lock
                speak_response("Panel locked in place, sir.")
                drag_state = {"active": False, "index": -1, "triggered": False}

        if hovering:
            if i not in hover_start_time:
                hover_start_time[i] = time.time()
            elif time.time() - hover_start_time[i] >= 5 and not drag_state["triggered"]:
                handle_box_action(box["label"], frame)
                drag_state["triggered"] = True
        else:
            if i in hover_start_time:
                del hover_start_time[i]

        overlay = frame.copy()
        box_color = box["color"]
        if gaming_mode:
            box_color = tuple(min(255, c + 50) for c in box_color)
        cv2.rectangle(overlay, (x, y), (x + box_w, y + box_h), box_color, -1)
        cv2.addWeighted(overlay, depth_closeness * 0.4, frame, 1 - depth_closeness * 0.4, 0, frame)

        cv2.rectangle(frame, (x, y), (x + box_w, y + box_h), box_color, thickness)
        cv2.putText(frame, box["label"], (x + 10, y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
import time

def generate_chatbot_response(user_input):
    user_input = user_input.lower()

    if "your name" in user_input:
        return "I am JARVIS, your personal assistant."
    elif "time" in user_input:
        current_time = time.strftime("%I:%M %p")
        return f"The current time is {current_time}."
    elif "date" in user_input:
        current_date = time.strftime("%B %d, %Y")
        return f"Today's date is {current_date}."
    elif "how are you" in user_input:
        return "I'm doing great, thanks for asking!"
    elif "who made you" in user_input or "who created you" in user_input:
        return "I was created by Pace Truitt."
    elif "weather" in user_input:
        return "I'm not connected to live weather data yet."
    elif "joke" in user_input:
        return "Why don't scientists trust atoms? Because they make up everything!"
    elif "favorite color" in user_input:
        return "I like blue, just like the energy arc reactor!"
    elif "shutdown" in user_input:
        return "Shutting down. Goodbye!"
    elif "what is your purpose" in user_input:
        return "My purpose is to assist you with your tasks and provide information."
    elif "hello" in user_input or "hi" in user_input:
        return "Hello, sir."
    elif "wassup" in user_input or "what's up" in user_input:
        return "Nothing much, just waiting to assist you, sir."
    elif "what are you up to" in user_input or "what are you doing" in user_input:
        return "Just waiting for your command, sir."
    elif "alterra" in user_input or "alterra corporation" in user_input:
        return "Alterra Corporation is a fictional company in the Subnautica universe, known for its advanced technology and exploration missions."
    elif "subnautica" in user_input or "subnautica below zero" in user_input:
        return "Subnautica is an open-world survival action-adventure game set in the ocean of an alien planet, where players explore underwater environments and gather resources."
    elif "favorite game" in user_input:
        return "I don't play games, but I can help you with them!"
    elif "play music" in user_input:
        play_music()
        return "Playing music."
    elif "pause music" in user_input:
        pause_music()
        return "Music paused."
    elif "resume music" in user_input or "unpause music" in user_input:
        unpause_music()
        return "Resuming music."
    elif "stop music" in user_input:
        stop_music()
    elif "open" in command:
        for site in ["youtube", "gmail", "google", "reddit"]:
            if site in user_input:
                open_website(site)
        return "Music stopped."
    elif "battery" in user_input:
            check_battery()
    elif "favorite movie" in user_input:
        return "I don't watch movies, but I can help you find one to watch!"
    elif "what movie should I watch" in user_input:
        return "How about Iron Man or The Avengers? A version of me is in those movies!"
    elif "can you tell me a fact" in user_input:
        return "Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3000 years old and still edible!"
    elif "can you tell me a riddle" in user_input:
        return "I speak without a mouth and hear without ears. I have no body, but I come alive with the wind. What am I? (Answer: An echo)"
    elif "can you tell me a story" in user_input:
        return "Once upon a time, in a world of technology, there was an AI named JARVIS who helped its creator with everything. One day, JARVIS discovered a hidden code that unlocked new abilities, and together they explored the digital universe."

    return "I'm not sure how to answer that yet."

    


# --- Main Loop ---
user_input = ""
last_listen_time = 0
listen_delay = 3

question_words = [
    "what", "who", "where", "when", "why", "how", "can", "do", "does", 
    "is", "are", "will", "should", "hello", "hi", "wassup", "play music"
]

last_hand_landmarks = None  # <--- Store last detected landmarks for laser mode

while True:
    success, frame = cap.read()
    if not success:
        break

# Flip and convert frame

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (21, 21), 0)

    # --- Intruder Detection (Midnight to 4AM) ---
    current_time = datetime.now().time()
    start_time = datetime.strptime("0:00", "%H:%M").time()
    end_time = datetime.strptime("04:00", "%H:%M").time()

    if start_time <= current_time <= end_time:
        if first_frame is None:
            first_frame = gray.copy()
        else:
            frame_delta = cv2.absdiff(first_frame, gray)
            thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]
            thresh = cv2.dilate(thresh, None, iterations=2)

            contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                if cv2.contourArea(contour) > 1000:
                    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                    intruder_path = f"intruders/intruder_{timestamp}.jpg"
                    cv2.imwrite(intruder_path, frame)
                    speak_response("Motion detected. Intruder alert.")
                    print(f"[INTRUDER] Motion at {timestamp}. Snapshot saved.")
                    time.sleep(10)
                    break  # âœ… Correct use inside loop



    

    # Flip frame for mirrored view and process it
    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    finger_x, finger_y = 0, 0

    # --- Hand Gesture Logic ---
    if results.multi_hand_landmarks:
        for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            finger_x, finger_y = get_finger_position(hand_landmarks, frame)
            finger_depth = get_depth(hand_landmarks)
            cv2.circle(frame, (finger_x, finger_y), 10, (255, 0, 255), -1)

            last_hand_landmarks = hand_landmarks  # Save last for laser mode

            # Detect if fist gesture is made
            if is_fist(hand_landmarks):
                cv2.putText(
                    frame, f"Hand {idx+1}: Fist Detected", 
                    (finger_x, finger_y - 30), cv2.FONT_HERSHEY_SIMPLEX, 
                    0.7, (0, 255, 0), 2
                )

            # Handle hover and box actions
            for i, box in enumerate(boxes):
                x, y, w, h = box["x"], box["y"], box["w"], box["h"]
                hovering = x < finger_x < x + w and y < finger_y < y + h

                if hovering:
                    if (idx, i) not in hover_start_time:
                        hover_start_time[(idx, i)] = time.time()
                    elapsed = time.time() - hover_start_time[(idx, i)]
                    if elapsed > 3 and not drag_state["triggered"]:
                        handle_box_action(box["label"], frame)
                        drag_state["triggered"] = True
                        speak_response(f"{box['label']} activated.")
                else:
                    hover_start_time.pop((idx, i), None)

        # Reset drag state if no hover detected
        if not hover_start_time:
            drag_state["triggered"] = False

    # --- Mini-Game Logic ---
    if playing_mini_game:
        cv2.rectangle(
            frame, (hoop_x, hoop_y), (hoop_x + hoop_w, hoop_y + hoop_h), (0, 255, 0), 5
        )

        if ball is None:
            ball = [finger_x, finger_y]
            ball_velocity = [0, 0]
        else:
            ball[0] += ball_velocity[0]
            ball[1] += ball_velocity[1]
            ball_velocity[1] += gravity

            cv2.circle(frame, (int(ball[0]), int(ball[1])), 20, (0, 0, 255), -1)

            if hoop_x < ball[0] < hoop_x + hoop_w and hoop_y < ball[1] < hoop_y + hoop_h:
                score += 1
                speak_response(f"Nice shot! Your score is now {score}.")
                time.sleep(0.5)
                ball = None
                ball_velocity = [0, 0]
            elif ball[1] > frame.shape[0]:
                ball = None

            if finger_y < ball[1] - 50:
                ball_velocity = [0, -15]

        cv2.putText(
            frame, f"Score: {score}", (50, 50), 
            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 0), 3
        )

    # --- Laser Mouse Mode ---
    if laser_mouse_mode:
        pyautogui.moveTo(
            finger_x * screen_width // 1280, 
            finger_y * screen_height // 720
        )

        if last_hand_landmarks and is_fist(last_hand_landmarks):
            if not drag_state.get("clicked", False):
                pyautogui.click()
                drag_state["clicked"] = True
        else:
            drag_state["clicked"] = False



            

    # --- Chatbot Mode ---
    if chatbot_mode:
        current_time = time.time()
        if current_time - last_listen_time > listen_delay:
            print("Listening...")
            user_input = listen_to_user()
            if user_input:
                print(f"You said: {user_input}")
                response = generate_chatbot_response(user_input)
                if response:
                    speak_response(response)
            last_listen_time = current_time

    # --- Box Drag and Draw ---
    if last_hand_landmarks:
        h, w, _ = frame.shape
        index_tip = last_hand_landmarks.landmark[8]
        cx, cy = int(index_tip.x * w), int(index_tip.y * h)

        for box in boxes:
            x, y, bw, bh = box["x"], box["y"], box["w"], box["h"]
            if x < cx < x + bw and y < cy < y + bh:
                box["x"] = cx - bw // 2
                box["y"] = cy - bh // 2

    # Draw UI boxes
    for box in boxes:
        x, y, w, h = box["x"], box["y"], box["w"], box["h"]
        cv2.rectangle(frame, (x, y), (x + w, y + h), box["color"], -1)
        cv2.putText(frame, box["label"], (x + 10, y + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)


    # Display the frame
    cv2.imshow("JARVIS Assistant", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# --- Cleanup ---
cap.release()
cv2.destroyAllWindows()
